#!/usr/bin/env python3
"""
TouchDesigner è¡¨æƒ…è¯†åˆ«äº¤äº’æ§åˆ¶å™¨
æœ¨é±¼æ•²å‡» â†’ è¡¨æƒ…è¯†åˆ« â†’ è®¾å¤‡æ•ˆæœæ¼”ç¤º â†’ å¾ªç¯
"""

import serial
import time
import cv2
import mediapipe as mp
import numpy as np
import threading
from enum import Enum
import queue

class SystemState(Enum):
    WAITING = "waiting"           # ç­‰å¾…æœ¨é±¼æ•²å‡»
    DETECTING = "detecting"       # è¡¨æƒ…è¯†åˆ«é˜¶æ®µ
    PERFORMING = "performing"     # è®¾å¤‡æ¼”ç¤ºé˜¶æ®µ
    COOLDOWN = "cooldown"         # å†·å´é˜¶æ®µ

class ExpressionType(Enum):
    HAPPY = 1      # å¼€å¿ƒ â†’ å½©è™¹æ•ˆæœ
    SAD = 2        # ä¼¤å¿ƒ â†’ è“è‰²é—ªç”µ  
    SURPRISE = 3   # æƒŠè®¶ â†’ ç´«è‰²è¿½é€

class FacialExpressionController:
    def __init__(self, serial_port='COM18', baud_rate=115200):
        # ç³»ç»ŸçŠ¶æ€
        self.current_state = SystemState.WAITING
        self.state_start_time = time.time()
        
        # é…ç½®å‚æ•°
        self.DETECTION_TIME = 3.0      # è¡¨æƒ…è¯†åˆ«æ—¶é—´ï¼ˆç§’ï¼‰
        self.PERFORMANCE_TIME = 10.0   # è®¾å¤‡æ¼”ç¤ºæ—¶é—´ï¼ˆç§’ï¼‰
        self.COOLDOWN_TIME = 2.0       # å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        
        # ä¸²å£é€šä¿¡
        self.serial_connection = None
        self.serial_port = serial_port
        self.baud_rate = baud_rate
        self.message_queue = queue.Queue()
        
        # MediaPipe åˆå§‹åŒ–
        self.mp_face_mesh = mp.solutions.face_mesh
        self.mp_drawing = mp.solutions.drawing_utils
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=False,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # æ‘„åƒå¤´
        self.cap = None
        self.camera_active = False
        
        # è¡¨æƒ…è¯†åˆ«ç»“æœ
        self.detected_expressions = []
        self.final_expression = None
        
        print("è¡¨æƒ…è¯†åˆ«æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def connect_serial(self):
        """è¿æ¥ä¸²å£"""
        try:
            self.serial_connection = serial.Serial(
                port=self.serial_port,
                baudrate=self.baud_rate,
                timeout=1
            )
            print(f"ä¸²å£è¿æ¥æˆåŠŸ: {self.serial_port}")
            
            # å¯åŠ¨ä¸²å£ç›‘å¬çº¿ç¨‹
            threading.Thread(target=self.serial_listener, daemon=True).start()
            return True
        except Exception as e:
            print(f"ä¸²å£è¿æ¥å¤±è´¥: {e}")
            return False
    
    def serial_listener(self):
        """ç›‘å¬ä¸²å£æ¶ˆæ¯"""
        while self.serial_connection and self.serial_connection.is_open:
            try:
                if self.serial_connection.in_waiting > 0:
                    data = self.serial_connection.readline().decode('utf-8', errors='ignore').strip()
                    if data:
                        self.message_queue.put(data)
                        print(f"æ”¶åˆ°æ¶ˆæ¯: {data}")
            except Exception as e:
                print(f"ä¸²å£è¯»å–é”™è¯¯: {e}")
                break
            time.sleep(0.01)
    
    def send_command(self, command):
        """å‘é€å‘½ä»¤åˆ°ESP32"""
        if self.serial_connection and self.serial_connection.is_open:
            try:
                cmd = command + '\n'
                self.serial_connection.write(cmd.encode('utf-8'))
                print(f"å‘é€å‘½ä»¤: {command}")
            except Exception as e:
                print(f"å‘é€å‘½ä»¤å¤±è´¥: {e}")
    
    def check_wooden_fish_hit(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æœ¨é±¼æ•²å‡»äº‹ä»¶"""
        while not self.message_queue.empty():
            message = self.message_queue.get()
            # æ£€æµ‹æœ¨é±¼æ•²å‡»å…³é”®è¯
            if any(keyword in message for keyword in [
                "WOODEN_FISH_HIT", "æœ¨é±¼è¢«æ•²å‡»", "æ•²å‡»æ£€æµ‹", "KNOCK_DETECTED"
            ]):
                print("ğŸ¥¢ æ£€æµ‹åˆ°æœ¨é±¼æ•²å‡»ï¼å¯åŠ¨äº¤äº’æµç¨‹")
                return True
        return False
    
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        if not self.camera_active:
            self.cap = cv2.VideoCapture(0)
            if self.cap.isOpened():
                self.camera_active = True
                print("ğŸ“· æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
                return True
            else:
                print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
                return False
        return True
    
    def stop_camera(self):
        """å…³é—­æ‘„åƒå¤´"""
        if self.camera_active and self.cap:
            self.cap.release()
            self.camera_active = False
            print("ğŸ“· æ‘„åƒå¤´å·²å…³é—­")
    
    def detect_expression(self, frame):
        """ä½¿ç”¨MediaPipeæ£€æµ‹è¡¨æƒ…"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_frame)
        
        if results.multi_face_landmarks:
            face_landmarks = results.multi_face_landmarks[0]
            
            # æå–å…³é”®ç‚¹åæ ‡
            h, w = frame.shape[:2]
            landmarks = []
            for lm in face_landmarks.landmark:
                landmarks.append([int(lm.x * w), int(lm.y * h)])
            
            # åˆ†æè¡¨æƒ…ç‰¹å¾
            expression = self.analyze_facial_features(landmarks)
            return expression
        
        return None
    
    def analyze_facial_features(self, landmarks):
        """åˆ†æé¢éƒ¨ç‰¹å¾åˆ¤æ–­è¡¨æƒ…"""
        # MediaPipeé¢éƒ¨å…³é”®ç‚¹ç´¢å¼•
        LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
        RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
        MOUTH_INDICES = [61, 84, 17, 314, 405, 321, 308, 324, 318]
        
        # è®¡ç®—çœ¼éƒ¨å¼€åˆåº¦
        left_eye_height = self.calculate_eye_aspect_ratio(landmarks, LEFT_EYE_INDICES[:6])
        right_eye_height = self.calculate_eye_aspect_ratio(landmarks, RIGHT_EYE_INDICES[:6])
        eye_ratio = (left_eye_height + right_eye_height) / 2
        
        # è®¡ç®—å˜´éƒ¨ç‰¹å¾
        mouth_ratio = self.calculate_mouth_aspect_ratio(landmarks, MOUTH_INDICES)
        
        # æ ¹æ®ç‰¹å¾åˆ¤æ–­è¡¨æƒ…
        if mouth_ratio > 0.05 and eye_ratio > 0.2:
            return ExpressionType.HAPPY
        elif eye_ratio < 0.15:
            return ExpressionType.SAD
        elif eye_ratio > 0.25 and mouth_ratio > 0.03:
            return ExpressionType.SURPRISE
        
        return None
    
    def calculate_eye_aspect_ratio(self, landmarks, eye_indices):
        """è®¡ç®—çœ¼éƒ¨é•¿å®½æ¯”"""
        if len(eye_indices) < 6:
            return 0
        
        # å‚ç›´è·ç¦»
        v1 = np.linalg.norm(np.array(landmarks[eye_indices[1]]) - np.array(landmarks[eye_indices[5]]))
        v2 = np.linalg.norm(np.array(landmarks[eye_indices[2]]) - np.array(landmarks[eye_indices[4]]))
        
        # æ°´å¹³è·ç¦»
        h = np.linalg.norm(np.array(landmarks[eye_indices[0]]) - np.array(landmarks[eye_indices[3]]))
        
        if h > 0:
            return (v1 + v2) / (2.0 * h)
        return 0
    
    def calculate_mouth_aspect_ratio(self, landmarks, mouth_indices):
        """è®¡ç®—å˜´éƒ¨é•¿å®½æ¯”"""
        if len(mouth_indices) < 6:
            return 0
        
        # å‚ç›´è·ç¦»ï¼ˆä¸Šå”‡åˆ°ä¸‹å”‡ï¼‰
        v = np.linalg.norm(np.array(landmarks[mouth_indices[2]]) - np.array(landmarks[mouth_indices[6]]))
        
        # æ°´å¹³è·ç¦»ï¼ˆå˜´è§’åˆ°å˜´è§’ï¼‰
        h = np.linalg.norm(np.array(landmarks[mouth_indices[0]]) - np.array(landmarks[mouth_indices[4]]))
        
        if h > 0:
            return v / h
        return 0
    
    def trigger_device_effect(self, expression):
        """æ ¹æ®è¡¨æƒ…è§¦å‘å¯¹åº”çš„è®¾å¤‡æ•ˆæœ"""
        print(f"ğŸ­ è§¦å‘è¡¨æƒ…æ•ˆæœ: {expression.name}")
        
        # å‘é€å¯¹åº”çš„æƒ…ç»ªå‘½ä»¤
        self.send_command(f"EMOTION:{expression.value}")
        
        # åŒæ—¶å¼€å¯LEDå¢å¼ºè§†è§‰æ•ˆæœ
        self.send_command("LED:1")
        
        # æ ¹æ®ä¸åŒè¡¨æƒ…æ·»åŠ ç‰¹æ®Šæ•ˆæœ
        if expression == ExpressionType.HAPPY:
            print("ğŸ˜Š å¼€å¿ƒæ¨¡å¼ - å½©è™¹æ•ˆæœ")
            # å¯ä»¥æ·»åŠ é¢å¤–çš„è®¾å¤‡æ§åˆ¶ï¼Œå¦‚å¯åŠ¨é›¾åŒ–å™¨
            # self.send_command("FOGGER:1")
            
        elif expression == ExpressionType.SAD:
            print("ğŸ˜¢ ä¼¤å¿ƒæ¨¡å¼ - è“è‰²é—ªç”µ")
            # å¯ä»¥æ·»åŠ ç”µæœºæŒ¯åŠ¨æ•ˆæœ
            # self.send_command("MOTOR:100:1")
            
        elif expression == ExpressionType.SURPRISE:
            print("ğŸ˜® æƒŠè®¶æ¨¡å¼ - ç´«è‰²è¿½é€")
            # å¯ä»¥æ·»åŠ éšæœºæ•ˆæœ
            # self.send_command("RANDOM:1:200:255")
    
    def stop_all_effects(self):
        """åœæ­¢æ‰€æœ‰è®¾å¤‡æ•ˆæœ"""
        print("â¹ï¸ åœæ­¢æ‰€æœ‰æ•ˆæœ")
        self.send_command("LED:0")
        self.send_command("MOTOR:0:0")
        self.send_command("FOGGER:0")
        self.send_command("RANDOM:0:0:0")
    
    def run_detection_phase(self):
        """è¿è¡Œè¡¨æƒ…è¯†åˆ«é˜¶æ®µ"""
        print("ğŸ” å¼€å§‹è¡¨æƒ…è¯†åˆ«...")
        self.detected_expressions = []
        
        if not self.start_camera():
            return None
        
        detection_start = time.time()
        
        while time.time() - detection_start < self.DETECTION_TIME:
            ret, frame = self.cap.read()
            if ret:
                # æ£€æµ‹è¡¨æƒ…
                expression = self.detect_expression(frame)
                if expression:
                    self.detected_expressions.append(expression)
                
                # æ˜¾ç¤ºæ£€æµ‹ç”»é¢ï¼ˆå¯é€‰ï¼‰
                cv2.putText(frame, f"Detecting... {int(self.DETECTION_TIME - (time.time() - detection_start))}s", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                if expression:
                    cv2.putText(frame, f"Expression: {expression.name}", 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
                
                cv2.imshow('Expression Detection', frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            time.sleep(0.03)  # ~30 FPS
        
        cv2.destroyAllWindows()
        self.stop_camera()
        
        # åˆ†ææ£€æµ‹ç»“æœï¼Œé€‰æ‹©æœ€é¢‘ç¹çš„è¡¨æƒ…
        if self.detected_expressions:
            from collections import Counter
            expression_counts = Counter(self.detected_expressions)
            final_expression = expression_counts.most_common(1)[0][0]
            print(f"ğŸ¯ æœ€ç»ˆè¯†åˆ«è¡¨æƒ…: {final_expression.name} (å‡ºç°{expression_counts[final_expression]}æ¬¡)")
            return final_expression
        else:
            print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¡¨æƒ…ï¼Œä½¿ç”¨é»˜è®¤å¼€å¿ƒè¡¨æƒ…")
            return ExpressionType.HAPPY
    
    def run_main_loop(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        print("ğŸš€ è¡¨æƒ…è¯†åˆ«äº¤äº’ç³»ç»Ÿå¯åŠ¨")
        print("ç­‰å¾…æœ¨é±¼æ•²å‡»æ¥å¼€å§‹äº¤äº’...")
        
        while True:
            current_time = time.time()
            elapsed_time = current_time - self.state_start_time
            
            if self.current_state == SystemState.WAITING:
                # ç­‰å¾…æœ¨é±¼æ•²å‡»
                if self.check_wooden_fish_hit():
                    self.current_state = SystemState.DETECTING
                    self.state_start_time = current_time
                    print("ğŸ­ è¿›å…¥è¡¨æƒ…è¯†åˆ«é˜¶æ®µ")
            
            elif self.current_state == SystemState.DETECTING:
                # è¡¨æƒ…è¯†åˆ«é˜¶æ®µ
                expression = self.run_detection_phase()
                if expression:
                    self.final_expression = expression
                    self.trigger_device_effect(expression)
                    self.current_state = SystemState.PERFORMING
                    self.state_start_time = current_time
                    print(f"ğŸª å¼€å§‹è®¾å¤‡æ¼”ç¤ºé˜¶æ®µ ({self.PERFORMANCE_TIME}ç§’)")
                else:
                    # è¯†åˆ«å¤±è´¥ï¼Œå›åˆ°ç­‰å¾…çŠ¶æ€
                    self.current_state = SystemState.WAITING
                    self.state_start_time = current_time
            
            elif self.current_state == SystemState.PERFORMING:
                # è®¾å¤‡æ¼”ç¤ºé˜¶æ®µ
                if elapsed_time >= self.PERFORMANCE_TIME:
                    self.stop_all_effects()
                    self.current_state = SystemState.COOLDOWN
                    self.state_start_time = current_time
                    print("ğŸ˜´ è¿›å…¥å†·å´é˜¶æ®µ")
                else:
                    # æ˜¾ç¤ºå‰©ä½™æ—¶é—´
                    remaining = int(self.PERFORMANCE_TIME - elapsed_time)
                    if remaining % 2 == 0:  # æ¯2ç§’æ‰“å°ä¸€æ¬¡
                        print(f"â° æ¼”ç¤ºä¸­... å‰©ä½™ {remaining} ç§’")
            
            elif self.current_state == SystemState.COOLDOWN:
                # å†·å´é˜¶æ®µ
                if elapsed_time >= self.COOLDOWN_TIME:
                    self.current_state = SystemState.WAITING
                    self.state_start_time = current_time
                    print("âœ… ç³»ç»Ÿå°±ç»ªï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡æœ¨é±¼æ•²å‡»...")
            
            time.sleep(0.1)  # ä¸»å¾ªç¯å»¶æ—¶
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ¸…ç†ç³»ç»Ÿèµ„æº...")
        self.stop_all_effects()
        self.stop_camera()
        if self.serial_connection and self.serial_connection.is_open:
            self.serial_connection.close()
        print("âœ… æ¸…ç†å®Œæˆ")

def main():
    # åˆ›å»ºæ§åˆ¶å™¨å®ä¾‹
    controller = FacialExpressionController(serial_port='COM3', baud_rate=115200)
    
    try:
        # è¿æ¥ä¸²å£
        if controller.connect_serial():
            # è¿è¡Œä¸»å¾ªç¯
            controller.run_main_loop()
        else:
            print("âŒ æ— æ³•è¿æ¥ä¸²å£ï¼Œè¯·æ£€æŸ¥è®¾å¤‡è¿æ¥")
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    
    finally:
        controller.cleanup()

if __name__ == "__main__":
    main() 